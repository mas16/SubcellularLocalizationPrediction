{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Tuning a Machine Learning Model to Predict Protein Subcellular Localization from Amino Acid Sequence\n",
    "\n",
    "by MAS, 06/2019\n",
    "\n",
    "### Introduction\n",
    "We now have access to an unprecedented amount of genomic information. However, harnessing the full potential of that information still requires a lot of slow and expensive experiments. In an ideal scenario, we would employ supervised machine learning to make predictions about biology using the data that's already been collected and readily available genomic information. **Here, I build and tune a machine learning model to predict the subcellular localization of proteins based on amino acid sequences.** The end result is a support vector machine (SVM) model that predicts soluble and membrane proteins with an out-of-sample prediction accuracy of 84%.\n",
    "\n",
    "### Data Preprocessing\n",
    "To build the model, we need protein amino acid sequences and data describing protein subcellular localization. Fortunately, the bacterium, *E. Coli* (species K12), has been studied to death so the subcellular localization of many of its proteins is known. Additionally, it's whole genome has been sequenced so all of its proteins' amino acid sequences are known. \n",
    "\n",
    "**For Simplicty we will only consider 2 classes for subcellular localization:**  \n",
    "\n",
    "   * In a membrane (\"membrane\")\n",
    "   * Not in a membrane (\"soluble\")\n",
    "\n",
    "The world's repository of protein data is [**Uniprot**](https://www.uniprot.org/help/proteomes_manual). Not only can we access every known protein sequence, we can also look up if a specific protein has had its subcellular localization characterized using its unique uniprot ID.\n",
    "\n",
    "I wrote a ```Python``` [script ```scrape_uniprot.py```](https://github.com/mas16/SubcellularLocalizationPrediction/blob/master/scrape_uniprot.py) (click link for code) to:\n",
    "\n",
    "> 1. Access Uniprot  \n",
    "> 2. Fetch the *E.Coli* protein sequences in [FASTA](https://en.wikipedia.org/wiki/FASTA_format) format  \n",
    "> 3. Extract the uniprot ID and animo acid sequence using regex   \n",
    "> 4. Query Uniprot using the uniprot ID  \n",
    "> 5. Scrape the subcellular localization if documented  \n",
    "> 6. Put everything together in a ```pandas``` dataframe and write to a ```.csv``` file\n",
    "\n",
    "Let's take a look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID                                           Sequence  Local\n",
      "0  A0A385XJ53  MASVSISCPSCSATDGVVRNGKSTAGHQRYLCSHCRKTWQLQFTYT...    NaN\n",
      "1  A0A385XJE6  MFVIWSHRTGFIMSHQLTFADSEFSSKRRQTRKEIFLSRMEQILPW...    NaN\n",
      "2  A0A385XJK5    MTLLQVHNFVDNSGRKKWLSRTLGQTRCPGKSMGREKFVKNNCSAIS    NaN\n",
      "3  A0A385XJL2   MLSTESWDNCEKPPLLFPFTALTCDETPVFSGSVLNLVAHSVDKYGIG    NaN\n",
      "4  A0A385XJL4  MPGNSPHYGRWPQHDFTSLKKLRPQSVTSRIQPGSDVIVCAEMDEQ...    NaN\n"
     ]
    }
   ],
   "source": [
    "# Preview the output from scrape_uniprot.py\n",
    "import pandas as pd\n",
    "\n",
    "# Path to output data\n",
    "datapath = \"/Users/matthewstetz/Documents/Projects/SubcellularLocalizationPrediction/\"\n",
    "\n",
    "df = pd.read_csv(datapath + \"ecoli_proteome.csv\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as you can see, a lot of annotations are missing. The script defines the classes to be:\n",
    "   * Membrane = 1\n",
    "   * Soluble = 0  \n",
    "\n",
    "So let's see how many of each class we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mebrane Count:  (1210, 3)\n",
      "Soluble Count:  (874, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mebrane Count: \", df[df[\"Local\"]==1].shape)\n",
    "print(\"Soluble Count: \", df[df[\"Local\"]==0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is a little bit of a class imbalance but we will deal with that when we build the model.\n",
    "\n",
    "### Feature Engineering\n",
    "Ok, now that we have our data in a tidy format, let's start engineering some features. Since the goal of this project is to only use genomic information, let's start by just counting the number of each amino acid. Of course, we need to normalize by the total number of amino acids since proteins can have very different lengths.\n",
    "\n",
    "We can also include some information derived from previous studies that relate amino acid count to specific chemical and physical properties. Specifically, let's use the relationship between amino acid and [hydrophobicity](https://web.expasy.org/protscale/pscale/Hphob.Doolittle.html) and [secondary structure](https://web.expasy.org/protscale/pscale/alpha-helixLevitt.html) as starting points since these are very well calibrated experimentally.\n",
    "\n",
    "I wrote a [script ```feature_extract.py```](https://github.com/mas16/SubcellularLocalizationPrediction/blob/master/feature_extract.py) which:\n",
    "> Reads dataframe with amino acid sequences  \n",
    "> Drops data without documented subcellular localization\n",
    "> Calculates normalized amino acid counts  \n",
    "> Calculates average hydrophobicity  \n",
    "> Calculates average seconday structure propensity \n",
    "> Writes features out to a tidy ```.csv``` output file\n",
    "\n",
    "Let's take a look at the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID                                           Sequence  Local         I  \\\n",
      "0  A5A605  MRLHVKLKEFLSMFFMAILFFPAFNASLFFTGVKPLYSIIKCSTEI...    1.0  0.132075   \n",
      "1  A5A615                    MNVSSRTVVLINFFAAVGLFTLISMRFGWFI    1.0  0.096774   \n",
      "2  A5A616                    MLGNMNVFMAVLGIILFSGFLAAYFSHKWDD    1.0  0.064516   \n",
      "3  A5A618                      MSTDLKFSLVTTIIVLGLIVAVGLTAALH    1.0  0.103448   \n",
      "4  A5A621                                MIERELGNWKDFIEVMLRK    0.0  0.105263   \n",
      "\n",
      "          V         L         F         C         M         A    ...     \\\n",
      "0  0.056604  0.106918  0.113208  0.025157  0.037736  0.056604    ...      \n",
      "1  0.129032  0.096774  0.161290  0.000000  0.064516  0.064516    ...      \n",
      "2  0.064516  0.129032  0.129032  0.000000  0.096774  0.096774    ...      \n",
      "3  0.137931  0.206897  0.034483  0.000000  0.034483  0.103448    ...      \n",
      "4  0.052632  0.105263  0.052632  0.000000  0.105263  0.000000    ...      \n",
      "\n",
      "          E         Q         D         N         K         R    X    U  \\\n",
      "0  0.018868  0.006289  0.018868  0.062893  0.075472  0.018868  0.0  0.0   \n",
      "1  0.000000  0.000000  0.000000  0.064516  0.000000  0.064516  0.0  0.0   \n",
      "2  0.000000  0.000000  0.064516  0.064516  0.032258  0.000000  0.0  0.0   \n",
      "3  0.000000  0.000000  0.034483  0.000000  0.034483  0.000000  0.0  0.0   \n",
      "4  0.157895  0.000000  0.052632  0.052632  0.105263  0.105263  0.0  0.0   \n",
      "\n",
      "   hydro_mean   ss_mean  \n",
      "0    0.753459  1.020692  \n",
      "1    1.341935  1.008065  \n",
      "2    0.929032  1.060645  \n",
      "3    1.634483  1.044483  \n",
      "4   -0.431579  1.139474  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(datapath + \"ecoli_proteome_features.csv\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the features. We want to make sure the features provide some information that can discriminate between soluble and membrane proteins without being colinear with other features.\n",
    "\n",
    "I wrote a [script ```evaluate_features.py```](https://github.com/mas16/SubcellularLocalizationPrediction/blob/master/evaluate_features.py) that does the following:\n",
    "\n",
    "> Reads dataframe of features  \n",
    "> Generates boxplots by classification for each feature   \n",
    "> Generates correlation matrix for all features  \n",
    "\n",
    "Let's see some output\n",
    "\n",
    "The amino acid alanine, \"A\", is roughly equally represented in soluble and membrane proteins:\n",
    "\n",
    "<img src=\"plots/A.png\" width=\"600\">\n",
    "\n",
    "The amino acid aspartatic acid, \"D\", is more represented in soluble proteins:\n",
    "\n",
    "<img src=\"plots/D.png\" width=\"600\">\n",
    "\n",
    "The correlation matrix shows the two features we calculated from the amino acid count: hydrophobicity ```hydro_mean``` and secondary structure propensity ```ss_mean``` are colinear with amino acid count so they are not going to be very useful in our model.\n",
    "\n",
    "<img src=\"plots/correlation_matrix.png\" width=\"800\">\n",
    "\n",
    "### Model Building and Evaluation\n",
    "\n",
    "Ok, now that we have our features and have evaluated whether or not they can be useful, let's use ```scikit-learn``` to build some models. Now, since this is a binary classification task, we can use the following models \n",
    "\n",
    "   * Logistic Regression\n",
    "   * Decision Trees\n",
    "   * Random Forests\n",
    "   * Gradient Boosted Trees\n",
    "   * Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2084, 27)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set seed\n",
    "seed = 1234\n",
    "\n",
    "# Read dataframe of features\n",
    "df = pd.read_csv(datapath + \"ecoli_proteome_features.csv\")\n",
    "\n",
    "# Final data set shape\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2084 observations. We have 24 features, 1 column of IDs, 1 column of classifications, 1 column of sequences for 27 columns total. We are cutting it a little close because we have ~2100 observations and 24 featurs. Ideally we would have 10x more observations than features but we already know some features are not useful based on our analysis above.\n",
    "\n",
    "Based on the box plots, we can eliminate alanine (A). U and X can also be eliminated because these are placeholders and not actual amino acids. We can also drop the ```ss_mean``` and ```hydro_mean``` because they are colinear with the other features. **This leaves a total of 19 features.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a total of ~ 2000 observations.\n",
    "# We should make sure our features are ~10x less than number of observations.\n",
    "\n",
    "# Based on the box plots, we can drop U, X, A,\n",
    "df = df.drop([\"U\", \"X\", \"A\"], axis=1)\n",
    "\n",
    "# Drop colinear features with abs(r) > 0.5\n",
    "df = df.drop([\"ss_mean\", \"hydro_mean\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's shuffle the data, do a train/validation split at 60:40, and standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "df = shuffle(df, random_state=seed)\n",
    "\n",
    "# Convert to np array\n",
    "array = df.values\n",
    "\n",
    "# Features\n",
    "X = array[:, 3:]\n",
    "X = X.astype(\"float\")\n",
    "\n",
    "# Classes\n",
    "Y = array[:, 2]\n",
    "Y = Y.astype(\"int\")\n",
    "\n",
    "# Size of test set\n",
    "test_size = 0.40\n",
    "\n",
    "# Test options and evaluation metric\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Set up train and validation sets\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "    model_selection.train_test_split(X, Y, test_size=test_size,\n",
    "                                     random_state=seed)\n",
    "\n",
    "# Standardize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the data are ready to go. Now we can evaluate our models. Let's do this empirically. First let's get our models from ```scikit-learn```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different models\n",
    "# Use default settings\n",
    "models = [('LR', LogisticRegression(solver=\"lbfgs\")), \n",
    "          ('CART', DecisionTreeClassifier()), \n",
    "          (\"RF\", RandomForestClassifier(n_estimators=100, random_state=seed)),\n",
    "          (\"GB\", GradientBoostingClassifier(n_estimators=100, \n",
    "                                            random_state=seed)), \n",
    "          ('SVM', SVC(gamma=\"scale\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's assess each models' accuracy using 5-fold cross validation. Here we will shuffle the data, divide the data into 5 equal parts, then iteratively train on 4/5 parts and test on the 5th part. We will do this for all combinations then average the resulting accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.7864000000000001 0.013047605144240084\n",
      "CART 0.7352000000000001 0.01741723284566181\n",
      "RF 0.8088 0.017959955456514888\n",
      "RF 0.8088 0.017959955456514888\n",
      "GB 0.8088 0.025474693324945036\n",
      "SVM 0.8288 0.025222212432695085\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # 5x cross validation\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train,\n",
    "                                                 cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(name, cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the 5x cross validation, GB, RF, and SVM perform within error of each other with SVM having the highest average accuracy. Let's start with SVM and tune the hyperparameters to see if we can improve the accuracy.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "Let's tune the hyperparameters using a grid search. The idea is to try a wide variety of parameters in every possible combination and empirically comparing the performance of the model. For SVM, we can change the kernel, the C value which reflects how soft the margins are, and the gamma value which reflects \"the inverse of the radius of influence of samples selected by the model as support vectors.\" For more information about SVM parameters, [click here](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html). Again, we will use 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "{'C': 5, 'gamma': 0.05}\n",
      "0.8272 0.02014348529922265\n",
      "linear\n",
      "{'C': 0.5, 'gamma': 0.001}\n",
      "0.7928 0.017959955456514895\n",
      "poly\n",
      "{'C': 0.001, 'gamma': 0.5}\n",
      "0.8160000000000001 0.02234278407003028\n",
      "sigmoid\n",
      "{'C': 10, 'gamma': 0.01}\n",
      "0.7928000000000001 0.02211243993773639\n"
     ]
    }
   ],
   "source": [
    "# SVM parameter tuning using 5 fold cross validation\n",
    "kernels = [\"rbf\", \"linear\", \"poly\", \"sigmoid\"]\n",
    "cv_results = []\n",
    "results = []\n",
    "nfolds = 5\n",
    "for kernel in kernels:\n",
    "    Cs = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "    gammas = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]\n",
    "    param_grid = {'C': Cs, 'gamma': gammas}\n",
    "    grid_search = GridSearchCV(SVC(kernel=kernel), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    c = grid_search.best_params_[\"C\"]\n",
    "    gamma = grid_search.best_params_[\"gamma\"]\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(SVC(kernel=kernel, C=c, gamma=gamma), \n",
    "                                                 X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    print(kernel)\n",
    "    print(grid_search.best_params_)\n",
    "    print(cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all of the kernels perform similarly and within error. The ```rbf``` kernel with ```C=5``` and ```gamma=0.05``` yielded the highest accuracy so let's try to apply that one to the test set.\n",
    "\n",
    "### Predicting the Test Set\n",
    "Now let's predict the test set data using the optimized SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Matrix: \n",
      "[[309  55]\n",
      " [ 80 390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       364\n",
      "           1       0.88      0.83      0.85       470\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       834\n",
      "   macro avg       0.84      0.84      0.84       834\n",
      "weighted avg       0.84      0.84      0.84       834\n",
      "\n",
      "Accuracy:  0.8381294964028777\n"
     ]
    }
   ],
   "source": [
    "# Apply final model to validation set\n",
    "classifier = SVC(kernel=\"rbf\", C=5, gamma=0.05)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_prediction = classifier.predict(X_test)\n",
    "print(\"Confustion Matrix: \")\n",
    "print(confusion_matrix(Y_test, Y_prediction))\n",
    "print(classification_report(Y_test, Y_prediction))\n",
    "print(\"Accuracy: \", accuracy_score(Y_test, Y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting for Class Imbalance\n",
    "We saw earlier that we had a class imbalance with 1210 observations of membrane proteins and 875 observations of soluble proteins. So it's not entirely surprising that we predict membrane proteins more accurately than soluble proteins. Let's try to compensate for this class imbalance by randomly sub-sampling the membranes proteins to the same number of observations as soluble proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.7904000000000002 0.02731739372634218\n",
      "CART 0.7432000000000001 0.018829763673503728\n",
      "RF 0.8168000000000001 0.022964320151051692\n",
      "RF 0.8168000000000001 0.022964320151051692\n",
      "GB 0.8064000000000002 0.005986651818838311\n",
      "SVM 0.828 0.018761663039293684\n"
     ]
    }
   ],
   "source": [
    "# Sub-sample the membrane proteins, data has already been shuffled\n",
    "balance_membrane_df = df[df[\"Local\"]==1].iloc[0:874,]\n",
    "\n",
    "balance_soluble_df = df[df[\"Local\"]==0]\n",
    "\n",
    "df_bal = pd.concat([balance_membrane_df, balance_soluble_df])\n",
    "\n",
    "# Shuffle the data again\n",
    "seed2 = 9999\n",
    "df_bal = shuffle(df, random_state=seed2)\n",
    "\n",
    "# Convert to np array\n",
    "array = df_bal.values\n",
    "\n",
    "# Features\n",
    "X = array[:, 3:]\n",
    "X = X.astype(\"float\")\n",
    "\n",
    "# Classes\n",
    "Y = array[:, 2]\n",
    "Y = Y.astype(\"int\")\n",
    "\n",
    "# Size of test set\n",
    "test_size = 0.40\n",
    "\n",
    "# Test options and evaluation metric\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Set up train and validation sets\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "    model_selection.train_test_split(X, Y, test_size=test_size,\n",
    "                                     random_state=seed)\n",
    "\n",
    "# Standardize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # 5x cross validation\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train,\n",
    "                                                 cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(name, cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see GB, RF, and SVM are still performing really similarly. Let's stick with SVM for now to compare to what we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "{'C': 1, 'gamma': 0.1}\n",
      "0.8256 0.015512575543732223\n",
      "linear\n",
      "{'C': 5, 'gamma': 0.001}\n",
      "0.7896000000000001 0.024344198487524685\n",
      "poly\n",
      "{'C': 0.001, 'gamma': 1}\n",
      "0.8088000000000001 0.01114271062174726\n",
      "sigmoid\n",
      "{'C': 10, 'gamma': 0.005}\n",
      "0.792 0.02234278407003029\n"
     ]
    }
   ],
   "source": [
    "# SVM parameter tuning using 5 fold cross validation\n",
    "kernels = [\"rbf\", \"linear\", \"poly\", \"sigmoid\"]\n",
    "cv_results = []\n",
    "results = []\n",
    "nfolds = 5\n",
    "for kernel in kernels:\n",
    "    Cs = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "    gammas = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]\n",
    "    param_grid = {'C': Cs, 'gamma': gammas}\n",
    "    grid_search = GridSearchCV(SVC(kernel=kernel), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    c = grid_search.best_params_[\"C\"]\n",
    "    gamma = grid_search.best_params_[\"gamma\"]\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(SVC(kernel=kernel, C=c, gamma=gamma), \n",
    "                                                 X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    print(kernel)\n",
    "    print(grid_search.best_params_)\n",
    "    print(cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apply the optimized SVM model to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Matrix: \n",
      "[[295  43]\n",
      " [ 93 403]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       338\n",
      "           1       0.90      0.81      0.86       496\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       834\n",
      "   macro avg       0.83      0.84      0.83       834\n",
      "weighted avg       0.85      0.84      0.84       834\n",
      "\n",
      "Accuracy:  0.8369304556354916\n"
     ]
    }
   ],
   "source": [
    "# Apply final model to validation set\n",
    "classifier = SVC(kernel=\"rbf\", C=5, gamma=0.01)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_prediction = classifier.predict(X_test)\n",
    "print(\"Confustion Matrix: \")\n",
    "print(confusion_matrix(Y_test, Y_prediction))\n",
    "print(classification_report(Y_test, Y_prediction))\n",
    "print(\"Accuracy: \", accuracy_score(Y_test, Y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the performance is similar so the class imbalance was not too severe. \n",
    "\n",
    "### Summary\n",
    "Here we showed that an SVM model using an ```rbf``` kernel, ```C=5```, and ```gamma=0.05``` was able to predict the subcellular localization of proteins with an out-of-sample accuracy of ~84%. Correcting for a slight class imbalance using random sub-sampling and re-training the model yielded a similar accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
